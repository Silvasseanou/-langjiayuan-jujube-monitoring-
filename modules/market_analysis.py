import requests
import pandas as pd
import numpy as np
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import json
import time
import random
from urllib.parse import urlencode

# ç½‘ç»œçˆ¬è™«åº“
import scrapy
from scrapy.crawler import CrawlerRunner
from scrapy.utils.log import configure_logging
from bs4 import BeautifulSoup
import selenium
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# æ•°æ®åˆ†æåº“
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import jieba
from textblob import TextBlob

# è‡ªç„¶è¯­è¨€å¤„ç†
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification

from config import Config
from models.database import MarketData, init_database

class DataCollector:
    """æ•°æ®æ”¶é›†å™¨"""
    
    def __init__(self, config: Config):
        self.config = config
        self.engine, self.Session = init_database(config.DATABASE_URL)
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
    def collect_ecommerce_data(self, platforms: List[str] = None) -> List[Dict]:
        """æ”¶é›†ç”µå•†å¹³å°æ•°æ®"""
        try:
            if platforms is None:
                platforms = ['taobao', 'tmall', 'jd', 'pinduoduo']
            
            all_data = []
            
            for platform in platforms:
                logging.info(f"Collecting data from {platform}")
                
                if platform == 'taobao':
                    data = self.collect_taobao_data()
                elif platform == 'tmall':
                    data = self.collect_tmall_data()
                elif platform == 'jd':
                    data = self.collect_jd_data()
                elif platform == 'pinduoduo':
                    data = self.collect_pdd_data()
                else:
                    continue
                
                all_data.extend(data)
                time.sleep(2)  # é¿å…è¯·æ±‚è¿‡å¿«
            
            return all_data
            
        except Exception as e:
            logging.error(f"Error collecting ecommerce data: {e}")
            return []
    
    def collect_taobao_data(self) -> List[Dict]:
        """æ”¶é›†æ·˜å®æ•°æ®ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        try:
            # å®é™…åº”ç”¨ä¸­éœ€è¦ä½¿ç”¨çœŸå®çš„APIæˆ–çˆ¬è™«
            # è¿™é‡Œè¿”å›æ¨¡æ‹Ÿæ•°æ®
            mock_data = []
            
            products = [
                "å†¬æ£", "æ–°ç–†å†¬æ£", "å’Œç”°å†¬æ£", "è‹¥ç¾Œå†¬æ£", "é˜¿å…‹è‹å†¬æ£",
                "éƒå®¶å›­å†¬æ£", "æœ‰æœºå†¬æ£", "æ— æ ¸å†¬æ£", "å¤§æ£", "å°æ£"
            ]
            
            for product in products:
                for i in range(10):
                    mock_data.append({
                        'platform': 'taobao',
                        'product_name': product,
                        'price': round(random.uniform(20, 200), 2),
                        'sales_volume': random.randint(100, 10000),
                        'rating': round(random.uniform(4.0, 5.0), 1),
                        'reviews_count': random.randint(50, 5000),
                        'shop_name': f"åº—é“º{i+1}",
                        'location': random.choice(['æ–°ç–†', 'æ²³åŒ—', 'å±±ä¸œ', 'æ²³å—', 'é™•è¥¿']),
                        'keywords': [product, 'å†¬æ£', 'å¹²æœ', 'é›¶é£Ÿ'],
                        'description': f"ä¼˜è´¨{product}ï¼Œäº§åœ°ç›´é”€",
                        'timestamp': datetime.now() - timedelta(days=random.randint(0, 30))
                    })
            
            return mock_data
            
        except Exception as e:
            logging.error(f"Error collecting Taobao data: {e}")
            return []
    
    def collect_tmall_data(self) -> List[Dict]:
        """æ”¶é›†å¤©çŒ«æ•°æ®ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        try:
            mock_data = []
            
            brands = [
                "è‰¯å“é“ºå­", "ç™¾è‰å‘³", "ä¸‰åªæ¾é¼ ", "æ¥ä¼Šä»½", "æ¥¼å…°èœœè¯­",
                "è¥¿åŸŸç¾å†œ", "éƒå®¶å›­", "é˜¿å…‹è‹å†œåœº", "å’Œç”°ç‰æ£"
            ]
            
            for brand in brands:
                for i in range(5):
                    mock_data.append({
                        'platform': 'tmall',
                        'product_name': f"{brand}å†¬æ£",
                        'price': round(random.uniform(30, 300), 2),
                        'sales_volume': random.randint(500, 20000),
                        'rating': round(random.uniform(4.5, 5.0), 1),
                        'reviews_count': random.randint(200, 10000),
                        'shop_name': f"{brand}å®˜æ–¹æ——èˆ°åº—",
                        'location': random.choice(['æ–°ç–†', 'æ²³åŒ—', 'å±±ä¸œ']),
                        'keywords': [brand, 'å†¬æ£', 'å“ç‰Œ', 'æ——èˆ°åº—'],
                        'description': f"{brand}å®˜æ–¹æ­£å“å†¬æ£",
                        'timestamp': datetime.now() - timedelta(days=random.randint(0, 30))
                    })
            
            return mock_data
            
        except Exception as e:
            logging.error(f"Error collecting Tmall data: {e}")
            return []
    
    def collect_jd_data(self) -> List[Dict]:
        """æ”¶é›†äº¬ä¸œæ•°æ®ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        try:
            mock_data = []
            
            for i in range(50):
                mock_data.append({
                    'platform': 'jd',
                    'product_name': f"å†¬æ£äº§å“{i+1}",
                    'price': round(random.uniform(25, 250), 2),
                    'sales_volume': random.randint(300, 15000),
                    'rating': round(random.uniform(4.2, 5.0), 1),
                    'reviews_count': random.randint(100, 8000),
                    'shop_name': f"äº¬ä¸œåº—é“º{i+1}",
                    'location': random.choice(['æ–°ç–†', 'æ²³åŒ—', 'å±±ä¸œ', 'æ²³å—']),
                    'keywords': ['å†¬æ£', 'å¹²æœ', 'è¥å…»', 'å¥åº·'],
                    'description': "ä¼˜è´¨å†¬æ£ï¼Œè¥å…»ä¸°å¯Œ",
                    'timestamp': datetime.now() - timedelta(days=random.randint(0, 30))
                })
            
            return mock_data
            
        except Exception as e:
            logging.error(f"Error collecting JD data: {e}")
            return []
    
    def collect_pdd_data(self) -> List[Dict]:
        """æ”¶é›†æ‹¼å¤šå¤šæ•°æ®ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        try:
            mock_data = []
            
            for i in range(30):
                mock_data.append({
                    'platform': 'pinduoduo',
                    'product_name': f"æ‹¼å¤šå¤šå†¬æ£{i+1}",
                    'price': round(random.uniform(15, 150), 2),
                    'sales_volume': random.randint(1000, 50000),
                    'rating': round(random.uniform(4.0, 4.8), 1),
                    'reviews_count': random.randint(500, 20000),
                    'shop_name': f"æ‹¼å¤šå¤šåº—é“º{i+1}",
                    'location': random.choice(['æ–°ç–†', 'æ²³åŒ—', 'å±±ä¸œ']),
                    'keywords': ['å†¬æ£', 'æ‹¼å›¢', 'ä¼˜æƒ ', 'å®æƒ '],
                    'description': "æ‹¼å›¢ä¼˜æƒ å†¬æ£",
                    'timestamp': datetime.now() - timedelta(days=random.randint(0, 30))
                })
            
            return mock_data
            
        except Exception as e:
            logging.error(f"Error collecting PDD data: {e}")
            return []
    
    def collect_social_media_data(self) -> List[Dict]:
        """æ”¶é›†ç¤¾äº¤åª’ä½“æ•°æ®"""
        try:
            # æ¨¡æ‹Ÿç¤¾äº¤åª’ä½“æ•°æ®
            mock_social_data = []
            
            platforms = ['weibo', 'douyin', 'xiaohongshu', 'zhihu']
            sentiments = ['positive', 'neutral', 'negative']
            
            for platform in platforms:
                for i in range(20):
                    mock_social_data.append({
                        'platform': platform,
                        'content': f"å…³äºå†¬æ£çš„{platform}å†…å®¹{i+1}",
                        'likes': random.randint(10, 10000),
                        'comments': random.randint(5, 1000),
                        'shares': random.randint(1, 500),
                        'sentiment': random.choice(sentiments),
                        'keywords': ['å†¬æ£', 'å¥åº·', 'ç¾é£Ÿ', 'è¥å…»'],
                        'timestamp': datetime.now() - timedelta(days=random.randint(0, 30))
                    })
            
            return mock_social_data
            
        except Exception as e:
            logging.error(f"Error collecting social media data: {e}")
            return []
    
    def save_data_to_db(self, data: List[Dict]):
        """ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“"""
        try:
            session = self.Session()
            
            for item in data:
                # è®¡ç®—æƒ…æ„Ÿåˆ†æ•°
                sentiment_score = self.calculate_sentiment_score(
                    item.get('description', '') + ' ' + item.get('content', '')
                )
                
                market_data = MarketData(
                    product_name=item.get('product_name', ''),
                    platform=item.get('platform', ''),
                    price=item.get('price', 0.0),
                    sales_volume=item.get('sales_volume', 0),
                    rating=item.get('rating', 0.0),
                    reviews_count=item.get('reviews_count', 0),
                    keywords=item.get('keywords', []),
                    sentiment_score=sentiment_score,
                    timestamp=item.get('timestamp', datetime.now())
                )
                
                session.add(market_data)
            
            session.commit()
            session.close()
            
            logging.info(f"Saved {len(data)} market data records to database")
            
        except Exception as e:
            logging.error(f"Error saving data to database: {e}")
    
    def calculate_sentiment_score(self, text: str) -> float:
        """è®¡ç®—æƒ…æ„Ÿåˆ†æ•°"""
        try:
            if not text:
                return 0.0
            
            # ä½¿ç”¨ç®€å•çš„æƒ…æ„Ÿè¯å…¸æ–¹æ³•
            positive_words = ['å¥½', 'æ£’', 'ä¼˜è´¨', 'ç¾å‘³', 'å¥åº·', 'è¥å…»', 'æ¨è', 'æ»¡æ„']
            negative_words = ['å·®', 'å', 'éš¾åƒ', 'ä¸å¥½', 'å¤±æœ›', 'é€€è´§', 'è´¨é‡å·®']
            
            positive_count = sum(1 for word in positive_words if word in text)
            negative_count = sum(1 for word in negative_words if word in text)
            
            if positive_count + negative_count == 0:
                return 0.0
            
            return (positive_count - negative_count) / (positive_count + negative_count)
            
        except Exception as e:
            logging.error(f"Error calculating sentiment score: {e}")
            return 0.0

class MarketAnalyzer:
    """å¸‚åœºåˆ†æå™¨"""
    
    def __init__(self, config: Config):
        self.config = config
        self.engine, self.Session = init_database(config.DATABASE_URL)
        
    def load_market_data(self, days: int = 30) -> pd.DataFrame:
        """åŠ è½½å¸‚åœºæ•°æ®"""
        try:
            session = self.Session()
            
            start_date = datetime.now() - timedelta(days=days)
            data = session.query(MarketData).filter(
                MarketData.timestamp >= start_date
            ).all()
            
            session.close()
            
            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame([{
                'product_name': row.product_name,
                'platform': row.platform,
                'price': row.price,
                'sales_volume': row.sales_volume,
                'rating': row.rating,
                'reviews_count': row.reviews_count,
                'keywords': row.keywords,
                'sentiment_score': row.sentiment_score,
                'timestamp': row.timestamp
            } for row in data])
            
            logging.info(f"Loaded {len(df)} market data records")
            return df
            
        except Exception as e:
            logging.error(f"Error loading market data: {e}")
            return pd.DataFrame()
    
    def analyze_price_trends(self, df: pd.DataFrame) -> Dict:
        """åˆ†æä»·æ ¼è¶‹åŠ¿"""
        try:
            if df.empty:
                return {}
            
            # æŒ‰å¹³å°åˆ†æä»·æ ¼
            platform_prices = df.groupby('platform')['price'].agg([
                'mean', 'median', 'min', 'max', 'std'
            ]).round(2)
            
            # æ—¶é—´åºåˆ—ä»·æ ¼åˆ†æ
            df['date'] = pd.to_datetime(df['timestamp']).dt.date
            daily_prices = df.groupby('date')['price'].mean()
            
            # ä»·æ ¼åŒºé—´åˆ†æ
            price_ranges = {
                'ä½ä»·(0-50)': len(df[df['price'] <= 50]),
                'ä¸­ä»·(50-100)': len(df[(df['price'] > 50) & (df['price'] <= 100)]),
                'é«˜ä»·(100-200)': len(df[(df['price'] > 100) & (df['price'] <= 200)]),
                'è¶…é«˜ä»·(200+)': len(df[df['price'] > 200])
            }
            
            return {
                'platform_analysis': platform_prices.to_dict(),
                'daily_trends': daily_prices.to_dict(),
                'price_ranges': price_ranges,
                'overall_stats': {
                    'average_price': round(df['price'].mean(), 2),
                    'median_price': round(df['price'].median(), 2),
                    'price_std': round(df['price'].std(), 2)
                }
            }
            
        except Exception as e:
            logging.error(f"Error analyzing price trends: {e}")
            return {}
    
    def analyze_consumer_preferences(self, df: pd.DataFrame) -> Dict:
        """åˆ†ææ¶ˆè´¹è€…åå¥½"""
        try:
            if df.empty:
                return {}
            
            # è¯„åˆ†åˆ†æ
            rating_analysis = {
                'average_rating': round(df['rating'].mean(), 2),
                'rating_distribution': df['rating'].value_counts().to_dict(),
                'high_rated_products': df[df['rating'] >= 4.5]['product_name'].value_counts().head(10).to_dict()
            }
            
            # é”€é‡åˆ†æ
            sales_analysis = {
                'total_sales': int(df['sales_volume'].sum()),
                'average_sales': round(df['sales_volume'].mean(), 2),
                'top_selling_products': df.nlargest(10, 'sales_volume')[['product_name', 'sales_volume']].to_dict('records')
            }
            
            # å…³é”®è¯åˆ†æ
            all_keywords = []
            for keywords in df['keywords']:
                if isinstance(keywords, list):
                    all_keywords.extend(keywords)
            
            keyword_counts = pd.Series(all_keywords).value_counts().head(20).to_dict()
            
            # æƒ…æ„Ÿåˆ†æ
            sentiment_analysis = {
                'average_sentiment': round(df['sentiment_score'].mean(), 2),
                'positive_ratio': round(len(df[df['sentiment_score'] > 0]) / len(df), 2),
                'negative_ratio': round(len(df[df['sentiment_score'] < 0]) / len(df), 2),
                'neutral_ratio': round(len(df[df['sentiment_score'] == 0]) / len(df), 2)
            }
            
            return {
                'rating_analysis': rating_analysis,
                'sales_analysis': sales_analysis,
                'keyword_analysis': keyword_counts,
                'sentiment_analysis': sentiment_analysis
            }
            
        except Exception as e:
            logging.error(f"Error analyzing consumer preferences: {e}")
            return {}
    
    def customer_segmentation(self, df: pd.DataFrame) -> Dict:
        """å®¢æˆ·ç»†åˆ†"""
        try:
            if df.empty or len(df) < 10:
                return {}
            
            # å‡†å¤‡ç‰¹å¾æ•°æ®
            features = df[['price', 'rating', 'sales_volume', 'sentiment_score']].fillna(0)
            
            # æ ‡å‡†åŒ–
            scaler = StandardScaler()
            features_scaled = scaler.fit_transform(features)
            
            # K-meansèšç±»
            n_clusters = min(4, len(features) // 3)  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®ç‚¹
            kmeans = KMeans(n_clusters=n_clusters, random_state=42)
            clusters = kmeans.fit_predict(features_scaled)
            
            # åˆ†ææ¯ä¸ªèšç±»
            df['cluster'] = clusters
            cluster_analysis = {}
            
            for cluster_id in range(n_clusters):
                cluster_data = df[df['cluster'] == cluster_id]
                
                cluster_analysis[f'cluster_{cluster_id}'] = {
                    'size': len(cluster_data),
                    'average_price': round(cluster_data['price'].mean(), 2),
                    'average_rating': round(cluster_data['rating'].mean(), 2),
                    'average_sales': round(cluster_data['sales_volume'].mean(), 2),
                    'average_sentiment': round(cluster_data['sentiment_score'].mean(), 2),
                    'top_products': cluster_data['product_name'].value_counts().head(5).to_dict()
                }
            
            return cluster_analysis
            
        except Exception as e:
            logging.error(f"Error in customer segmentation: {e}")
            return {}
    
    def market_opportunity_analysis(self, df: pd.DataFrame) -> Dict:
        """å¸‚åœºæœºä¼šåˆ†æ"""
        try:
            if df.empty:
                return {}
            
            # ä»·æ ¼-è´¨é‡è±¡é™åˆ†æ
            price_threshold = df['price'].median()
            rating_threshold = df['rating'].median()
            
            quadrants = {
                'high_price_high_quality': len(df[(df['price'] > price_threshold) & (df['rating'] > rating_threshold)]),
                'high_price_low_quality': len(df[(df['price'] > price_threshold) & (df['rating'] <= rating_threshold)]),
                'low_price_high_quality': len(df[(df['price'] <= price_threshold) & (df['rating'] > rating_threshold)]),
                'low_price_low_quality': len(df[(df['price'] <= price_threshold) & (df['rating'] <= rating_threshold)])
            }
            
            # å¸‚åœºç©ºç™½åˆ†æ
            market_gaps = []
            
            # é«˜è´¨é‡ä½ä»·ä½äº§å“æœºä¼š
            if quadrants['low_price_high_quality'] < quadrants['high_price_high_quality']:
                market_gaps.append("é«˜è´¨é‡ä½ä»·ä½äº§å“å­˜åœ¨å¸‚åœºæœºä¼š")
            
            # å¹³å°æœºä¼šåˆ†æ
            platform_performance = df.groupby('platform').agg({
                'sales_volume': 'sum',
                'rating': 'mean',
                'price': 'mean'
            }).round(2)
            
            best_platform = platform_performance['sales_volume'].idxmax()
            
            return {
                'price_quality_quadrants': quadrants,
                'market_gaps': market_gaps,
                'platform_performance': platform_performance.to_dict(),
                'recommended_platform': best_platform,
                'opportunities': [
                    "å…³æ³¨é«˜è´¨é‡ä½ä»·ä½äº§å“å¼€å‘",
                    f"é‡ç‚¹å…³æ³¨{best_platform}å¹³å°",
                    "æå‡äº§å“è¯„åˆ†å’Œç”¨æˆ·ä½“éªŒ"
                ]
            }
            
        except Exception as e:
            logging.error(f"Error in market opportunity analysis: {e}")
            return {}
    
    def generate_market_report(self) -> Dict:
        """ç”Ÿæˆå¸‚åœºåˆ†ææŠ¥å‘Š"""
        try:
            # åŠ è½½æ•°æ®
            df = self.load_market_data()
            
            if df.empty:
                return {'error': 'æ²¡æœ‰è¶³å¤Ÿçš„å¸‚åœºæ•°æ®'}
            
            # æ‰§è¡Œå„é¡¹åˆ†æ
            price_analysis = self.analyze_price_trends(df)
            consumer_analysis = self.analyze_consumer_preferences(df)
            segmentation = self.customer_segmentation(df)
            opportunity_analysis = self.market_opportunity_analysis(df)
            
            # ç”ŸæˆæŠ¥å‘Š
            report = {
                'report_date': datetime.now().isoformat(),
                'data_summary': {
                    'total_products': len(df),
                    'platforms_covered': df['platform'].nunique(),
                    'date_range': {
                        'start': df['timestamp'].min().strftime('%Y-%m-%d'),
                        'end': df['timestamp'].max().strftime('%Y-%m-%d')
                    }
                },
                'price_analysis': price_analysis,
                'consumer_analysis': consumer_analysis,
                'customer_segmentation': segmentation,
                'market_opportunities': opportunity_analysis,
                'recommendations': self.generate_recommendations(
                    price_analysis, consumer_analysis, opportunity_analysis
                )
            }
            
            return report
            
        except Exception as e:
            logging.error(f"Error generating market report: {e}")
            return {'error': str(e)}
    
    def generate_recommendations(self, price_analysis: Dict, consumer_analysis: Dict, 
                               opportunity_analysis: Dict) -> List[str]:
        """ç”Ÿæˆå»ºè®®"""
        try:
            recommendations = []
            
            # ä»·æ ¼å»ºè®®
            if price_analysis.get('overall_stats', {}).get('average_price', 0) > 100:
                recommendations.append("å¸‚åœºå¹³å‡ä»·æ ¼è¾ƒé«˜ï¼Œå¯è€ƒè™‘æ¨å‡ºæ€§ä»·æ¯”äº§å“")
            
            # è´¨é‡å»ºè®®
            avg_rating = consumer_analysis.get('rating_analysis', {}).get('average_rating', 0)
            if avg_rating < 4.5:
                recommendations.append("å¸‚åœºæ•´ä½“è¯„åˆ†åä½ï¼Œé«˜å“è´¨äº§å“æœ‰ç«äº‰ä¼˜åŠ¿")
            
            # å¹³å°å»ºè®®
            best_platform = opportunity_analysis.get('recommended_platform', '')
            if best_platform:
                recommendations.append(f"å»ºè®®é‡ç‚¹å…³æ³¨{best_platform}å¹³å°")
            
            # äº§å“å»ºè®®
            top_keywords = list(consumer_analysis.get('keyword_analysis', {}).keys())[:3]
            if top_keywords:
                recommendations.append(f"äº§å“è¥é”€å¯é‡ç‚¹çªå‡ºï¼š{', '.join(top_keywords)}")
            
            # æƒ…æ„Ÿå»ºè®®
            sentiment = consumer_analysis.get('sentiment_analysis', {})
            if sentiment.get('negative_ratio', 0) > 0.2:
                recommendations.append("æ³¨æ„è´Ÿé¢è¯„ä»·ï¼Œæå‡äº§å“å’ŒæœåŠ¡è´¨é‡")
            
            return recommendations
            
        except Exception as e:
            logging.error(f"Error generating recommendations: {e}")
            return []

class BrandPromotion:
    """å“ç‰Œæ¨å¹¿æ¨¡å—"""
    
    def __init__(self, config: Config):
        self.config = config
        
    def generate_brand_story(self, brand_name: str = "éƒå®¶å›­") -> str:
        """ç”Ÿæˆå“ç‰Œæ•…äº‹"""
        try:
            story_template = f"""
ã€{brand_name}å†¬æ£çš„æ•…äº‹ã€‘

åœ¨å¤ä¸ç»¸ä¹‹è·¯çš„å¿…ç»ä¹‹åœ°ï¼Œæœ‰ä¸€ä¸ªåå«{brand_name}çš„å°æ‘åº„ã€‚è¿™é‡Œå››å­£åˆ†æ˜ï¼Œæ—¥ç…§å……è¶³ï¼Œæ˜¼å¤œæ¸©å·®å¤§ï¼Œæ˜¯å¤©ç„¶çš„å†¬æ£ç§æ¤å®åœ°ã€‚

æ•°ç™¾å¹´æ¥ï¼Œ{brand_name}çš„æ‘æ°‘ä»¬ä¸–ä»£ç§æ¤å†¬æ£ï¼Œä»–ä»¬ç”¨æœ€æœ´ç´ çš„æ–¹å¼ï¼Œéµå¾ªç€è‡ªç„¶çš„èŠ‚æ‹ã€‚æ˜¥å¤©æ’­ç§å¸Œæœ›ï¼Œå¤å¤©ç²¾å¿ƒå‘µæŠ¤ï¼Œç§‹å¤©æ”¶è·ç”˜ç”œï¼Œå†¬å¤©ä¸ºæ¥å¹´åšå‡†å¤‡ã€‚

æ¯ä¸€é¢—{brand_name}å†¬æ£ï¼Œéƒ½ç»è¿‡äº†æ—¶é—´çš„æ´—ç¤¼å’Œé˜³å…‰çš„æ»‹å…»ã€‚æˆ‘ä»¬åšæŒï¼š
- å¤©ç„¶ç§æ¤ï¼Œä¸ä½¿ç”¨åŒ–å­¦å†œè¯
- äººå·¥ç²¾é€‰ï¼Œæ¯é¢—å†¬æ£éƒ½ç»è¿‡ä¸¥æ ¼ç­›é€‰
- ä¼ ç»Ÿå·¥è‰ºï¼Œä¿æŒåŸæ±åŸå‘³
- ç°ä»£ç§‘æŠ€ï¼Œç¡®ä¿é£Ÿå“å®‰å…¨

{brand_name}å†¬æ£ï¼Œä¸ä»…æ˜¯ä¸€ç§é£Ÿç‰©ï¼Œæ›´æ˜¯ä¸€ç§æ–‡åŒ–çš„ä¼ æ‰¿ï¼Œä¸€ç§å¯¹ç¾å¥½ç”Ÿæ´»çš„è¿½æ±‚ã€‚æ¯ä¸€å£éƒ½æ˜¯å¤§è‡ªç„¶çš„é¦ˆèµ ï¼Œæ¯ä¸€é¢—éƒ½æ‰¿è½½ç€å†œæ°‘çš„å¿ƒè¡€ã€‚

é€‰æ‹©{brand_name}ï¼Œé€‰æ‹©å¥åº·ï¼Œé€‰æ‹©ä¼ ç»Ÿï¼Œé€‰æ‹©å“è´¨ã€‚
è®©æˆ‘ä»¬ä¸€èµ·å“å‘³æ—¶å…‰çš„ç”˜ç”œï¼Œæ„Ÿå—å¤§è‡ªç„¶çš„æ©èµã€‚

{brand_name}å†¬æ£ - ä¼ æ‰¿ç™¾å¹´çš„ç”˜ç”œå›å¿†
            """
            
            return story_template.strip()
            
        except Exception as e:
            logging.error(f"Error generating brand story: {e}")
            return ""
    
    def generate_product_descriptions(self, product_info: Dict) -> List[str]:
        """ç”Ÿæˆäº§å“æè¿°"""
        try:
            descriptions = []
            
            # åŸºç¡€æè¿°
            base_desc = f"""
{product_info.get('name', 'ä¼˜è´¨å†¬æ£')} - æ¥è‡ª{product_info.get('origin', 'æ–°ç–†')}çš„å¤©ç„¶é¦ˆèµ 

äº§å“ç‰¹ç‚¹ï¼š
âœ“ æœå®é¥±æ»¡ï¼Œè‚‰è´¨ç´§å®
âœ“ ç”œåº¦é€‚ä¸­ï¼Œå£æ„Ÿé¦™ç”œ
âœ“ è¥å…»ä¸°å¯Œï¼Œå«æœ‰ä¸°å¯Œçš„ç»´ç”Ÿç´ Cå’Œé“å…ƒç´ 
âœ“ æ— æ·»åŠ å‰‚ï¼Œå¤©ç„¶å¥åº·

é€‚å®œäººç¾¤ï¼š
â€¢ åŠå…¬å®¤ç™½é¢†ï¼Œè¡¥å……èƒ½é‡
â€¢ äº§å¦‡åæœˆå­ï¼Œè¡¥è¡€å…»é¢œ
â€¢ è€å¹´äººï¼Œå¢å¼ºä½“è´¨
â€¢ å„¿ç«¥ï¼Œå¥åº·é›¶é£Ÿ

é£Ÿç”¨æ–¹æ³•ï¼š
â†’ ç›´æ¥é£Ÿç”¨ï¼Œå½“ä½œé›¶é£Ÿ
â†’ æ³¡æ°´é¥®ç”¨ï¼Œåˆ¶ä½œæ£èŒ¶
â†’ ç…®ç²¥ç…²æ±¤ï¼Œè¥å…»æ­é…
â†’ åˆ¶ä½œç³•ç‚¹ï¼Œçƒ˜ç„™åŸæ–™
            """
            
            descriptions.append(base_desc)
            
            # è¥é”€æè¿°
            marketing_desc = f"""
ğŸ”¥ é™æ—¶ç‰¹æƒ  ğŸ”¥ {product_info.get('name', 'ä¼˜è´¨å†¬æ£')}

ã€ä¸ºä»€ä¹ˆé€‰æ‹©æˆ‘ä»¬ã€‘
ğŸŒŸ æºäº§åœ°ç›´ä¾›ï¼Œçœå»ä¸­é—´ç¯èŠ‚
ğŸŒŸ å†œæˆ·ç²¾é€‰ï¼Œå“è´¨ä¿è¯
ğŸŒŸ ä¼ ç»Ÿå·¥è‰ºï¼Œç°ä»£åŒ…è£…
ğŸŒŸ é¡ºä¸°é…é€ï¼Œæ–°é²œåˆ°å®¶

ã€å®¢æˆ·å¥½è¯„ã€‘
"å£æ„Ÿå¾ˆå¥½ï¼Œç”œåº¦åˆšå¥½ï¼Œå­©å­å¾ˆå–œæ¬¢"
"åŒ…è£…ç²¾ç¾ï¼Œé€‚åˆé€ç¤¼"
"æ€§ä»·æ¯”å¾ˆé«˜ï¼Œä¼šå›è´­"

ã€è´´å¿ƒæé†’ã€‘
ğŸ”¸ å¯†å°ä¿å­˜ï¼Œé¿å…å—æ½®
ğŸ”¸ é€‚é‡é£Ÿç”¨ï¼Œå‡è¡¡é¥®é£Ÿ
ğŸ”¸ å¦‚æœ‰ç–‘é—®ï¼Œéšæ—¶å’¨è¯¢å®¢æœ

ç«‹å³ä¸‹å•ï¼Œäº«å—å¥åº·ç¾å‘³ï¼
            """
            
            descriptions.append(marketing_desc)
            
            return descriptions
            
        except Exception as e:
            logging.error(f"Error generating product descriptions: {e}")
            return []
    
    def generate_social_media_content(self, content_type: str = "general") -> List[str]:
        """ç”Ÿæˆç¤¾äº¤åª’ä½“å†…å®¹"""
        try:
            contents = []
            
            if content_type == "health":
                health_content = [
                    "ğŸ æ¯æ—¥ä¸€æŠŠå†¬æ£ï¼Œå…»è¡€è¡¥æ°”èº«ä½“å¥½ï¼å†¬æ£å¯Œå«ç»´ç”Ÿç´ Cï¼Œæ˜¯å¤©ç„¶çš„ç¾å®¹åœ£å“ #å¥åº·ç”Ÿæ´» #å†¬æ£å…»ç”Ÿ",
                    "ğŸŒŸ ç†¬å¤œåŠ ç­åæ¥å‡ é¢—å†¬æ£ï¼Œè¡¥å……èƒ½é‡åˆå…»é¢œï¼ä¸Šç­æ—çš„å¿…å¤‡å°é›¶é£Ÿ #èŒåœºå¥åº· #å†¬æ£èƒ½é‡",
                    "ğŸ‘¶ å®å¦ˆä»¬æ³¨æ„äº†ï¼å†¬æ£æ˜¯äº§åæ¢å¤çš„å¥½å¸®æ‰‹ï¼Œè¡¥è¡€å…»é¢œä¸¤ä¸è¯¯ #å®å¦ˆå¿…å¤‡ #äº§åæ¢å¤",
                    "ğŸ§“ è€å¹´äººåƒå†¬æ£ç›Šå¤„å¤šå¤šï¼šå¢å¼ºå…ç–«åŠ›ã€æ”¹å–„ç¡çœ ã€å»¶ç¼“è¡°è€ #å­æ•¬çˆ¶æ¯ #å¥åº·å…»ç”Ÿ"
                ]
                contents.extend(health_content)
            
            elif content_type == "recipe":
                recipe_content = [
                    "ğŸ¥˜ å†¬æ£é“¶è€³æ±¤åšæ³•ï¼šé“¶è€³æ³¡å‘+å†¬æ£å»æ ¸+å†°ç³–ï¼Œç‚–ç…®2å°æ—¶ï¼Œç¾å®¹å…»é¢œï¼#ç¾é£Ÿæ•™ç¨‹ #å…»ç”Ÿæ±¤å“",
                    "ğŸ å†¬æ£é¢åŒ…è‡ªåˆ¶æ³•ï¼šé¢ç²‰+å†¬æ£ç¢+é…µæ¯ï¼Œå‘é…µçƒ˜çƒ¤ï¼Œé¦™ç”œå¯å£ï¼#çƒ˜ç„™æ—¥è®° #å¥åº·é¢åŒ…",
                    "ğŸµ å†¬æ£èŒ¶çš„ç§˜å¯†ï¼šå†¬æ£+æ¸æ+èœ‚èœœï¼Œçƒ­æ°´å†²æ³¡ï¼Œæ¸©æš–ä¸€æ•´å¤©ï¼#å…»ç”ŸèŒ¶é¥® #å†¬æ—¥æš–èº«",
                    "ğŸš å†¬æ£å°ç±³ç²¥ï¼šå°ç±³+å†¬æ£+æ¡‚åœ†ï¼Œæ…¢ç«ç†¬ç…®ï¼Œè¥å…»æ—©é¤é¦–é€‰ï¼#è¥å…»æ—©é¤ #å¥åº·ç²¥å“"
                ]
                contents.extend(recipe_content)
            
            elif content_type == "culture":
                culture_content = [
                    "ï¿½ï¿½ï¸ å†¬æ£æ–‡åŒ–å°çŸ¥è¯†ï¼šåœ¨å¤ä»£ï¼Œå†¬æ£è¢«ç§°ä¸º\"æœ¨æœ¬ç²®é£Ÿ\"ï¼Œæ˜¯é‡è¦çš„è¥å…»æ¥æº #ä¼ ç»Ÿæ–‡åŒ– #é£Ÿç‰©å†å²",
                    "ğŸ æ–°ç–†å†¬æ£çš„æ•…äº‹ï¼šå¾—å¤©ç‹¬åšçš„åœ°ç†ç¯å¢ƒï¼Œé€ å°±äº†ä¸–ç•Œä¸Šæœ€å¥½çš„å†¬æ£ #æ–°ç–†ç‰¹äº§ #åœ°ç†æ ‡å¿—",
                    "ğŸŠ èŠ‚æ—¥é€ç¤¼æ–°é€‰æ‹©ï¼šå†¬æ£å¯“æ„\"æ—©ç”Ÿè´µå­\"ï¼Œæ˜¯ä¼ ç»Ÿçš„å‰ç¥¥é£Ÿå“ #èŠ‚æ—¥ç¤¼å“ #ä¼ ç»Ÿå¯“æ„",
                    "ğŸ“š è¯—è¯ä¸­çš„å†¬æ£ï¼šå¤äººäº‘\"æ—¥é£Ÿä¸‰æ£ï¼Œé•¿ç”Ÿä¸è€\", ä½“ç°äº†å†¬æ£çš„è¥å…»ä»·å€¼ #å¤è¯—è¯ #å…»ç”Ÿæ™ºæ…§"
                ]
                contents.extend(culture_content)
            
            else:
                general_content = [
                    "ğŸŒ… ç¾å¥½çš„ä¸€å¤©ä»ä¸€é¢—å†¬æ£å¼€å§‹ï¼å¤©ç„¶ç”œèœœï¼Œå¥åº·ç¾å‘³ #æ—©å®‰ #å¥åº·ç”Ÿæ´»",
                    "ğŸ¯ éƒå®¶å›­å†¬æ£æ–°å“ä¸Šå¸‚ï¼é™æ—¶ç‰¹æƒ ï¼ŒæŠ¢è´­ä»é€Ÿï¼#æ–°å“æ¨è #é™æ—¶ä¼˜æƒ ",
                    "ğŸ“¦ åŒ…é‚®åˆ°å®¶ï¼Œæ–°é²œå†¬æ£ç›´è¾¾æ‚¨çš„é¤æ¡Œï¼#åŒ…é‚®æœåŠ¡ #æ–°é²œç›´è¾¾",
                    "â­ äº”æ˜Ÿå¥½è¯„å¦‚æ½®ï¼æ„Ÿè°¢æ¯ä¸€ä½ä¿¡ä»»æˆ‘ä»¬çš„å®¢æˆ· #å®¢æˆ·å¥½è¯„ #å“è´¨ä¿è¯"
                ]
                contents.extend(general_content)
            
            return contents
            
        except Exception as e:
            logging.error(f"Error generating social media content: {e}")
            return []
    
    def generate_advertisement_copy(self, ad_type: str = "general") -> Dict:
        """ç”Ÿæˆå¹¿å‘Šæ–‡æ¡ˆ"""
        try:
            if ad_type == "video":
                return {
                    'title': 'éƒå®¶å›­å†¬æ£ - ä¼ æ‰¿ç™¾å¹´çš„ç”˜ç”œ',
                    'script': """
                    é•œå¤´1ï¼šæ–°ç–†å¹¿è¢¤çš„å†¬æ£å›­ï¼Œé˜³å…‰æ´’åœ¨å†¬æ£æ ‘ä¸Š
                    æ—ç™½ï¼šåœ¨å¤ä¸ç»¸ä¹‹è·¯çš„èµ·ç‚¹ï¼Œæœ‰ä¸€ç‰‡ç¥å¥‡çš„åœŸåœ°
                    
                    é•œå¤´2ï¼šå†œæ°‘ç²¾å¿ƒé‡‡æ‘˜å†¬æ£çš„åœºæ™¯
                    æ—ç™½ï¼šæ¯ä¸€é¢—å†¬æ£ï¼Œéƒ½ç»è¿‡æ—¶é—´çš„æ´—ç¤¼
                    
                    é•œå¤´3ï¼šå†¬æ£çš„ç‰¹å†™ï¼Œå±•ç°é¥±æ»¡çš„æœå®
                    æ—ç™½ï¼šå¤©ç„¶ç”˜ç”œï¼Œè¥å…»ä¸°å¯Œ
                    
                    é•œå¤´4ï¼šå®¶äººå›´åï¼Œåˆ†äº«å†¬æ£çš„æ¸©é¦¨åœºæ™¯
                    æ—ç™½ï¼šéƒå®¶å›­å†¬æ£ï¼Œä¼ é€’çš„ä¸ä»…æ˜¯ç”˜ç”œï¼Œæ›´æ˜¯æ¸©æš–
                    
                    ç»“å°¾ï¼šéƒå®¶å›­å†¬æ£ LOGO
                    æ—ç™½ï¼šéƒå®¶å›­å†¬æ£ï¼Œä¼ æ‰¿ç™¾å¹´çš„ç”˜ç”œå›å¿†
                    """,
                    'duration': '30ç§’',
                    'target_audience': '25-45å²å®¶åº­æ¶ˆè´¹è€…'
                }
            
            elif ad_type == "poster":
                return {
                    'title': 'å¤©ç„¶ç”˜ç”œ è¥å…»ä¸°å¯Œ',
                    'main_text': 'éƒå®¶å›­å†¬æ£\næ¥è‡ªæ–°ç–†çš„å¤©ç„¶é¦ˆèµ ',
                    'sub_text': 'æ— æ·»åŠ  â€¢ åŸäº§åœ°ç›´ä¾› â€¢ ä¼ ç»Ÿå·¥è‰º',
                    'call_to_action': 'ç«‹å³è´­ä¹°ï¼Œäº«å—å¥åº·ç¾å‘³',
                    'color_scheme': 'çº¢è‰²ä¸»è°ƒï¼Œé‡‘è‰²è£…é¥°',
                    'layout': 'å†¬æ£äº§å“å›¾ + æ–‡æ¡ˆ + è´­ä¹°æŒ‰é’®'
                }
            
            elif ad_type == "banner":
                return {
                    'title': 'é™æ—¶ç‰¹æƒ ï¼éƒå®¶å›­å†¬æ£5æŠ˜èµ·',
                    'content': 'æ–°ç–†åŸäº§åœ°ç›´ä¾› â€¢ åŒ…é‚®åˆ°å®¶ â€¢ å“è´¨ä¿è¯',
                    'cta_button': 'ç«‹å³æŠ¢è´­',
                    'urgency': 'ä»…é™ä»Šæ—¥ï¼Œå”®å®Œå³æ­¢',
                    'size': '750x300px'
                }
            
            else:
                return {
                    'headline': 'éƒå®¶å›­å†¬æ£ - å¥åº·ç”Ÿæ´»çš„ç”œèœœé€‰æ‹©',
                    'body': 'æ¥è‡ªæ–°ç–†çš„å¤©ç„¶å†¬æ£ï¼Œç»è¿‡ä¼ ç»Ÿå·¥è‰ºç²¾åˆ¶è€Œæˆã€‚å¯Œå«ç»´ç”Ÿç´ Cå’Œé“å…ƒç´ ï¼Œæ˜¯æ‚¨å’Œå®¶äººçš„å¥åº·é¦–é€‰ã€‚',
                    'features': [
                        'å¤©ç„¶æ— æ·»åŠ ',
                        'è¥å…»ä¸°å¯Œ',
                        'å£æ„Ÿç”˜ç”œ',
                        'åŒ…è£…ç²¾ç¾'
                    ],
                    'call_to_action': 'ç«‹å³è®¢è´­ï¼Œäº«å—å¥åº·ç¾å‘³'
                }
            
        except Exception as e:
            logging.error(f"Error generating advertisement copy: {e}")
            return {}
    
    def create_promotional_campaign(self, campaign_type: str = "seasonal") -> Dict:
        """åˆ›å»ºæ¨å¹¿æ´»åŠ¨"""
        try:
            if campaign_type == "seasonal":
                return {
                    'campaign_name': 'æ˜¥èŠ‚å›¢åœ†Â·éƒå®¶å›­å†¬æ£ç¤¼ç›’',
                    'duration': '2024å¹´1æœˆ15æ—¥ - 2024å¹´2æœˆ28æ—¥',
                    'theme': 'å›¢åœ†å¹´å‘³ï¼Œç”œèœœåˆ†äº«',
                    'activities': [
                        {
                            'type': 'æ»¡å‡ä¼˜æƒ ',
                            'details': 'æ»¡98å…ƒå‡20å…ƒï¼Œæ»¡198å…ƒå‡50å…ƒ'
                        },
                        {
                            'type': 'èµ å“æ´»åŠ¨',
                            'details': 'è´­ä¹°ç¤¼ç›’è£…èµ é€ç²¾ç¾æ‰‹æè¢‹'
                        },
                        {
                            'type': 'æ‹¼å›¢æ´»åŠ¨',
                            'details': '3äººæˆå›¢äº«å—8æŠ˜ä¼˜æƒ '
                        }
                    ],
                    'promotion_channels': [
                        'ç”µå•†å¹³å°é¦–é¡µæ¨å¹¿',
                        'ç¤¾äº¤åª’ä½“å¹¿å‘ŠæŠ•æ”¾',
                        'çº¿ä¸‹é—¨åº—å±•ç¤º',
                        'ç¤¾åŒºæ¨å¹¿æ´»åŠ¨'
                    ],
                    'target_metrics': {
                        'sales_target': 'æå‡30%',
                        'brand_awareness': 'å¢åŠ 25%',
                        'new_customers': 'è·å–1000åæ–°å®¢æˆ·'
                    }
                }
            
            elif campaign_type == "health":
                return {
                    'campaign_name': 'å¥åº·ç”Ÿæ´»Â·å†¬æ£å…»ç”Ÿæœˆ',
                    'duration': '30å¤©',
                    'theme': 'å¤©ç„¶å…»ç”Ÿï¼Œå¥åº·ç”Ÿæ´»',
                    'activities': [
                        {
                            'type': 'å¥åº·ç§‘æ™®',
                            'details': 'æ¯æ—¥å‘å¸ƒå†¬æ£å…»ç”Ÿå°çŸ¥è¯†'
                        },
                        {
                            'type': 'é£Ÿè°±åˆ†äº«',
                            'details': 'å†¬æ£ç¾é£Ÿåˆ¶ä½œæ•™ç¨‹'
                        },
                        {
                            'type': 'ç”¨æˆ·äº’åŠ¨',
                            'details': 'åˆ†äº«å…»ç”Ÿå¿ƒå¾—èµ¢å¥–å“'
                        }
                    ],
                    'promotion_channels': [
                        'å¥åº·ç±»å¾®ä¿¡å…¬ä¼—å·',
                        'å…»ç”Ÿç±»APPåˆä½œ',
                        'åŒ»é™¢è¥å…»ç§‘æ¨è',
                        'å¥èº«æˆ¿åˆä½œæ¨å¹¿'
                    ],
                    'target_metrics': {
                        'engagement_rate': 'æå‡40%',
                        'content_views': '100ä¸‡+',
                        'user_interaction': '10ä¸‡+äº’åŠ¨'
                    }
                }
            
            return {}
            
        except Exception as e:
            logging.error(f"Error creating promotional campaign: {e}")
            return {}

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    config = Config()
    
    # æ•°æ®æ”¶é›†
    collector = DataCollector(config)
    ecommerce_data = collector.collect_ecommerce_data()
    social_data = collector.collect_social_media_data()
    
    # ä¿å­˜æ•°æ®
    collector.save_data_to_db(ecommerce_data + social_data)
    
    # å¸‚åœºåˆ†æ
    analyzer = MarketAnalyzer(config)
    report = analyzer.generate_market_report()
    
    print("å¸‚åœºåˆ†ææŠ¥å‘Š:")
    print(json.dumps(report, indent=2, ensure_ascii=False))
    
    # å“ç‰Œæ¨å¹¿
    promoter = BrandPromotion(config)
    brand_story = promoter.generate_brand_story()
    social_content = promoter.generate_social_media_content("health")
    
    print("\nå“ç‰Œæ•…äº‹:")
    print(brand_story)
    
    print("\nç¤¾äº¤åª’ä½“å†…å®¹:")
    for content in social_content:
        print(f"- {content}") 